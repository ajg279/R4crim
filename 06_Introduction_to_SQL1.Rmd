---
title: "Introduction to SQL"
author:
- affiliation: University of Pennsylvania
  email: gridge@upenn.edu
  name: Greg Ridgeway
- affiliation: University of Pennsylvania
  email: moyruth@upenn.edu
  name: Ruth Moyer
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    css: htmlstyle.css
---

<!-- HTML YAML header Ctrl-Shift-C to comment/uncomment -->


<!-- --- -->
<!-- title: "Introduction to SQL" -->
<!-- author: -->
<!-- - Greg Ridgeway (gridge@upenn.edu) -->
<!-- - Ruth Moyer (moyruth@upenn.edu) -->
<!-- date: "`r format(Sys.time(), '%B %d, %Y')`" -->
<!-- output: -->
<!--   pdf_document: -->
<!--     latex_engine: pdflatex -->
<!--   html_document: default -->
<!-- fontsize: 11pt -->
<!-- fontfamily: mathpazo -->
<!-- --- -->
<!-- PDF YAML header Ctrl-Shift-C to comment/uncomment -->

<!-- Make RMarkdown cache the results -->
```{r echo=FALSE}
knitr::opts_chunk$set(echo=TRUE, cache=TRUE, cache.lazy=FALSE)
```

<!-- A function for autmomating the numbering and wording of the exercise questions -->
```{r echo=FALSE}
.counterExercise <- 0
.exerciseQuestions <- NULL
.exNum <- function(.questionText="") 
{
   .counterExercise <<- .counterExercise+1
   .exerciseQuestions <<- c(.exerciseQuestions, .questionText)
   return(paste0(.counterExercise,". ",.questionText))
}
```

#Introduction to SQL

Some datasets are far too large for R to handle by itself. Structured Query Language ("SQL") is a widely used international standard language for managing data stored in databases. There are numerous relational database management systems such as Oracle, Microsoft Access, and MySQL. We are going to use [SQLite](https://www.sqlite.org/index.html), which is probably the most widely deployed database system. SQLite is in your phone, car, airplanes, thermostats, and numerous applicances. We are going to hook up SQLite to R so that R can handle large datasets.

These are some basic clauses in a SQL query that we will explore:

SELECT    	fields or functions of fields
INTO      	results table
FROM      	tables queried
WHERE     	conditions for selecting a record
GROUP BY  	list of fields to group
ORDER BY  	list of fields to sort by

However, before being able to use SQL as a tool in R, it will first be necessary to install the `sqldf` package.

```{r comment="", results='hold'} 
library(sqldf)
```

# Getting the data into proper form

We will be working with Chicago crime data, which is accessible comma separated value (csv) format. Before we can even being learning SQL, we are going to have to do a fair bit of work to acquire the dataset, format it so that it's ready for SQLite, and then load it into the SQLite database.

Navigate to the Chicago open data website to get the [data](https://data.cityofchicago.org/Public-Safety/Crimes-2001-to-present/ijzp-q8t2). Click the "Export" button and select the "CSV" option, or directly download from [here](https://data.cityofchicago.org/api/views/ijzp-q8t2/rows.csv?accessType=DOWNLOAD)

The Chicago crime data is huge, more than 1.5Gb. It contains about 7 million records on all crimes reported to the Chicago police department since 2001. R does not handle really large datasets well. By using SQL, you will learn how to more efficiently work with large datasets and learn a data language that is used absolutely everywhere.

Let's use `scan()` to just peek at the first three rows of the file.

```{r comment="", results='hold'} 
scan(what="",file="Crimes_-_2001_to_present.csv",nlines=5,sep="\n")
```
`scan()` is a very basic R function that reads in plain text files. We've told it to read in text (`what==""`), the name of the file, to only read in 5 lines (`nlines=5`), and to start a new row whenever it reaches a line feed character (`sep="\n"`). Using `scan()` without `nlines=5` would cause R to try to read in the whole dataset and that could take a lot of time and you might run out of memory.

You can see that the first row contains the column names. The second row contains the first reported crime in the file. You can see date and time, address, crime descriptions, longitude and latitude of the crime, and other information.

Importantly, SQLite is very particular about the formatting of a file. It can easily read in a csv file, but this dataset has some commas in places that confuse SQLite.

For example, there is a row in this file that looks like this:

```{r comment="", results='hold', echo=FALSE} 
print("10000153,HY189345,03/18/2015 12:20:00 PM,091XX S UNIVERSITY AVE,0483,BATTERY,AGG PRO.EMP: OTHER DANG WEAPON,\"SCHOOL, PUBLIC, BUILDING\",true,false,0413,004,8,47,04B,1185475,1844606,2015,02/10/2018 03:50:01 PM,41.728740563,-87.596150779,\"(41.728740563, -87.596150779)\"")
```

You see that the location description for this crime is `"SCHOOL, PUBLIC, BUILDING"`. Those commas inside the quotes are going to cause SQLite problems. SQLite is going to think that `SCHOOL`, `PUBLIC`, and `BUILDING` are all separate columns rather than one columns describing the location.

To resolve this, we're going to change all the commas that separate the columns into something else besides commas, leaving the commas in elements like `"SCHOOL, PUBLIC, BUILDING"` alone. It does not matter what we use to separate the fields, but it should be an unusual character that would not appear anywhere else in the dataset. Popular choices in the vertical bar (`|`) and the semi-colon (`;`). So let's take a slight detour to find out how to convert a comma-separated file into a semi-colon separated file. 

You'll know if you need to convert your file if, when you try to set up your SQL database, you receive an error message about an "extra column."

We're going to use a `while` loop to read in 1,000,000 rows of the our data file at a time. R can handle 1,000,000 rows. With the 1,000,000 rows read in, we'll use a regular expression to replace all the commas used for separating columns with semi-colons. Then we'll write out the resulting cleaned up rows into a new file. It is a big file so this code can take a few minutes to run to completion.

```{r comment="", results='hold', echo=FALSE, R.options=list(scipen=999)} 
infile  <- file("Crimes_-_2001_to_present.csv", 'r')       # 'r' for 'read'
outfile <- file("Crimes_-_2001_to_present-clean.csv", 'w') # 'w' for 'write'

cLines <- 0 # just a counter for the number of lines read

# read in 1000000 lines. keep going if more than 0 lines read
while ((length(a <- readLines(infile, n=1000000)) > 0))
{
   cLines <- cLines + length(a) # increase the line counter
   print(cLines)
   # remove any semi-colons if they are there
   a <- gsub(";", "", a)
   # use ?= to "lookahead" for paired quotes
   a <- gsub("(,)(?=(?:[^\"]|\"[^\"]*\")*$)", ";", a, perl=TRUE)
   # write the cleaned up data to storage
   writeLines(a, con=outfile)
}
close(infile)
close(outfile)
```

Now, let's take a look at the first five lines of the new file we just created.
```{r comment="", results='hold'} 
scan(what="",file="Crimes_-_2001_to_present-clean.csv",nlines=5,sep="\n")
```
You now see that semi-colons separate the columns rather than commas. That previous record that had the location description "SCHOOL, PUBLIC, BUILDING" now looks like this:
```{r comment="", results='hold', echo=FALSE} 
print("10000153;HY189345;03/18/2015 12:20:00 PM;091XX S UNIVERSITY AVE;0483;BATTERY;AGG PRO.EMP: OTHER DANG WEAPON;\"SCHOOL, PUBLIC, BUILDING\";true;false;0413;004;8;47;04B;1185475;1844606;2015;02/10/2018 03:50:01 PM;41.728740563;-87.596150779;\"(41.728740563, -87.596150779)\"")
```
Note that the commas are still there inside the quotes. Now we will be able to tell SQLite to look for semi-colons to separate the columns.

# Setting up the Database

Now that the file containing the data is ready, we can load it into SQLite. SQLite has its own way of storing and managing data. It can store multiple tables containing data in a single database. First, we'll tell SQLite to create a new database that we will call `chicagocrime`. Then we will tell SQLite to load our data file into a table called `crime`.

The next step is to set up the SQL database. The following lines of code will set up the database for you.  Make sure that your path is set correctly so that your database will be stored in the correct folder that you wish to work from. You will know if the database has been successfully set up if the database (stored as a .db file) is greater than 0 KB.  there is no reason to run these lines of code again. 

```{r comment="", results='hold'}
# create a connection to the database
con <- dbConnect(SQLite(), dbname="chicagocrime.db")
# just in case you've already created a "crime" table, delete it
if(dbExistsTable(con, "crime")) dbRemoveTable(con, "crime")
# import the data file into the database
dbWriteTable(con, "crime",                         # create crime table   
             "Crimes_-_2001_to_present-clean.csv", # from our cleaned up file
             row.names=FALSE,
             header=TRUE,                          # first row has column names
             sep=";")                              # columns separated with ;
# a quick check to see if all the columns are there
dbListFields(con,"crime")
# disconnect from the database to finalize
dbDisconnect(con)
```

Once you've successfully set up your database, there is no reason to run these lines of code again. You should never again need to turn commas into semi-colons or run `dbWriteTable()`. Instead, every time you want to work with your database, you can simply need to reconnect to the database with: 
```{r comment="", results='hold'} 
con <- dbConnect(SQLite(), dbname="chicagocrime.db")
```
(Note that if you're keeping you are using a cloud-based backup service like iCloud, OneDrive, or Google Drive, you might need to wait until your "db" file has completely "synced" before you can access your database.)

# SQL queries
You've now created a database (called "chicagocrime.db") containing a table called "crime" that contains those 7 million crime records. 

Two important clauses with an SQL query are `SELECT` and `FROM`. Unlike R, SQL queries are not case-sensitive. Unlike in R, the column names in SQL aren't case-sensitive. So if we were to type "SELECT" as "select" or "Description" as "dEsCrIpTiOn", the SQL query would do the same thing. However, the tradition is to type SQL keywords in all uppercase to make it easier to distinguish them from table and column names.

The `SELECT` clause tells SQL which columns in particular you would like to see. The `FROM` clause simply tells SQL from which table it should pull the data. In this query, we are interested in only the `ID` and `Description` columns.  

```{r comment="", results='hold'} 
res <- dbSendQuery(con, "
                   SELECT ID, Description
                   FROM crime")
fetch(res, n = 10) # just the first 10 rows
dbClearResult(res)
```

Here, we set `n=10` so the first 10 rows are displayed. By convention, setting `n=-1`, will display all your rows. Really large SQL queries can be memory-intensive. So if your dataset is over 25 lines long (which it probably is.....that's why you're using SQL!), you have to make sure that you set the value in the fetch line to something reasonable to display.

However, suppose that your dataset is over 1 million rows, and you want to work with all of them.  You can set the `fetch` line to something like `mydata <- fetch(res, n=-1)`. 

`dbClearResult(res)` tells SQLite that we are all done with this query. We've retrieved the first 10 lines. SQLite is standing by with another 7 million rows to show us, but `dbClearResult(res)` tells SQLite that we are no longer interested in this query and it can clear out whatever it has stored for us.

In the previous SQL query we just asked for `ID` and `Description`. Typing out all of the column names would be tiresome, so SQL lets you use a `*` to select all the columns. If we want to look at the first 10 rows but all of the columns, we would use this query:
```{r comment="", results='hold'} 
res <- dbSendQuery(con, "
                   SELECT *
                   FROM crime")
fetch(res, n = 10) # just the first 10 rows
dbClearResult(res)
```

Just as `SELECT` filters the columns, the `WHERE` clause filters the rows. Note the use of `AND` and `OR` in the `WHERE` clause. As you might intuitively guess, `AND` and `OR` are logical operators that help us further filter our rows. Here we select three columns: `ID`, `Description`, and `LocationDescription`. Also, we want only rows where 
* the value in the "Beat" column is "611"
* the value in the "Arrest" column is "true"
* the value in ICUR column is either "0486" or "0498"

Importantly, note the use of single (not double) quotation marks in the WHERE line. Also, note how we set the "fetch" line to the variable a. 

```{r comment="", results='hold'} 
res <- dbSendQuery(con, "
                   SELECT ID,Description,LocationDescription
                   FROM crime
                   WHERE ((Beat=611) AND (Arrest='true')) AND
                         ((IUCR='0486') OR (IUCR='0498'))")
a <- fetch(res, n = -1) # all the rows
dbClearResult(res)
```

# Practice Exercises
1. Select records from Beat 234

```{r comment="", results='hold'} 
res <- dbSendQuery(con, "
          SELECT *
          FROM crime
          WHERE ((Beat=234))") 
a <- fetch(res, n = -1) 
dbClearResult(res)
```

2. Select Beat, District, Ward, and Community Area for all 'ASSAULT's

```{r comment="", results='hold'} 
res <- dbSendQuery(con, "
                  SELECT Beat, District, Ward, CommunityArea, PrimaryType
                  FROM crime
                  WHERE ((PrimaryType='ASSAULT'))") 
a <- fetch(res, n = -1) 
dbClearResult(res)
```

3. Select records on assaults from Beat 234

```{r comment="", results='hold'} 
res <- dbSendQuery(con, "
                    SELECT *
                    FROM crime
                    WHERE ((Beat=234) AND (PrimaryType='ASSAULT'))") 
a <- fetch(res, n = -1) 
dbClearResult(res)
```

4. Make a table in R of the number of assaults (IUCR 0560) by Ward.

```{r comment="", results='hold'} 
res <- dbSendQuery(con, "
                  SELECT *
                  FROM crime
                  WHERE ((IUCR='0560') AND (PrimaryType='ASSAULT'))") 
a <- fetch(res, n = -1) 
dbClearResult(res)
table(a$Ward)
```

Or, we could also try selecting all the IUCR codes and ward - and then subsetting the data through R.  "The system.time" R command allows us to see how long it takes to run the SQL query. 

```{r comment="", results='hold'} 
system.time(
  {
    res <- dbSendQuery(con, "
                       SELECT IUCR,Ward
                       FROM crime")
    data <- fetch(res, n = -1)
    dbClearResult(res)
  })

data1 <- subset(data, PrimaryType=="ASSAULT" & IUCR=="0560")
```

#More SQL commands

We've already covered SQL commands such as SELECT and WHERE. The commands COUNT(*) and GROUP BY are also very useful. For example,

```{r comment="", results='hold'} 
system.time(
{
res <- dbSendQuery(con, "
   SELECT COUNT(*) AS crimecount,
          Ward
   FROM crime
   WHERE IUCR='0560'
   GROUP BY Ward")
a <- fetch(res, n = -1)
dbClearResult(res)
})
```

What does the GROUP BY command do?  What function does the COUNT(*) command have? 

# Practice exercises
1. Count the number of crimes by PrimaryType

```{r comment="", results='hold'} 
res <- dbSendQuery(con, "
              SELECT COUNT(*) AS count, PrimaryType
              FROM crime
              GROUP BY PrimaryType")
fetch(res, n = -1)
dbClearResult(res)
```


2. Count the number of crimes resulting in arrest

```{r comment="", results='hold'} 
res <- dbSendQuery(con, "
                   SELECT COUNT(*) AS count, PrimaryType
                   FROM crime
                   WHERE Arrest='true'
                   GROUP BY PrimaryType")
fetch(res, n = -1)
dbClearResult(res)
```


Or, if we weren't interested in differentiating based on the PrimaryType, we could simply do the following:

```{r comment="", results='hold'} 
res <- dbSendQuery(con, "
                   SELECT COUNT(*) AS count
                   FROM crime
                   WHERE Arrest='true'")
fetch(res, n = -1)
dbClearResult(res)
```

3. Count the number of crimes by LocationDescription.  LocationDescription is the variable that tells us where (meaning,e.g., a parking lot, a barbershop, a fire station, a CTA train, or a motel) a crime occurred.

```{r comment="", results='hold'} 
res <- dbSendQuery(con, "
SELECT COUNT(*) AS count,
                   LocationDescription
                   FROM crime
                   GROUP BY LocationDescription")
fetch(res, n = -1)
dbClearResult(res)
```

#More useful SQL tools

Also, MAX, MIN, SUM, AVG are common (and useful) aggregating functions. the function ORDER BY sorts the results for us.  It's a bit like the SQL version of the sort() command.  Here is an illustration:

```{r comment="", results='hold'} 
res <- dbSendQuery(con, "
   SELECT MIN(Beat) AS min_beat,
          MAX(Beat) AS max_beat,
          District
   FROM crime
   GROUP BY District
   ORDER BY District")
fetch(res, n = -1)
dbClearResult(res)
```

Let's look at our Latitude and Longitude columns (which, as we find in a subsequent section, will be extremely useful for mapping data points).  The following query will give unexpected results for MAX. The problem is that there are empty values in some entries. 

```{r comment="", results='hold'} 
res <- dbSendQuery(con, "
   SELECT MIN(Latitude)  AS min_lat,
          MAX(Latitude)  AS max_lat,
          MIN(Longitude) AS min_lon,
          MAX(Longitude) AS max_lon,
          District
   FROM crime
   WHERE (Latitude IS NOT NULL) AND
         (Longitude IS NOT NULL)
   GROUP BY District
   ORDER BY District")
fetch(res, n = -1)
dbClearResult(res)
```


Note that row 41 has some problems. Our latitude and longitude values are both 0, which would occur in the middle of the Atlantic Ocean. Obviously, that coordinate location is not within Chicago. So, in all likelihood, we simply have missing coordinates data in a row like 41.  

Note the XCoordinate and the YCoordinate columns. They simply give the location per the State Plane Illinois East NAD 1983 projection.

```{r comment="", results='hold'} 
res <- dbSendQuery(con, "
   SELECT *
   FROM crime
   WHERE ROWID<=41")
fetch(res, n = -1)
dbClearResult(res)
```

Let's look at what line 41 is in the raw text that we read in:
```{r comment="", results='hold'} 
scan(what="",file="Crimes_-_2001_to_present-clean.csv",sep="\n",nlines=42)
```

We can tell SQLite to make the empty values NULL.  The UPDATE command edits our table. R will now read in the NULL values as NA.  After we do the update, we can rerun the MIN, MAX query. Note that some are our latitudes and longitudes are very close to 0, but not exactly 0; we can make those NULL as well. 

```{r comment="", results='hold'} 
res <- dbSendQuery(con, "
   UPDATE crime SET XCoordinate=NULL
   WHERE (XCoordinate='') OR (XCoordinate=0)")
res <- dbSendQuery(con, "
   UPDATE crime SET YCoordinate=NULL
   WHERE (YCoordinate='') OR (YCoordinate=0)")
res <- dbSendQuery(con, "
   UPDATE crime SET Latitude=NULL
   WHERE (Latitude='') OR (ABS(Latitude-0.0)<0.01)")
res <- dbSendQuery(con, "
   UPDATE crime SET Longitude=NULL
   WHERE (Longitude='') OR (ABS(Longitude-0.0)<0.01)")
```

Let's reexamine the (X,Y) coordinates

```{r comment="", results='hold'} 
res <- dbSendQuery(con, "
   SELECT ID,XCoordinate,YCoordinate,Latitude,Longitude
   FROM crime")
a <- fetch(res, n = -1)
dbClearResult(res)
a[1:10,]
```

And what city does the following plot have the shape of?

```{r comment="", results='hold'} 
i <- sample(1:nrow(a),10000)
plot(a$Longitude[i],a$Latitude[i],pch=".",xlab="Longitude",ylab="Latitude")
```

# Practice exercises
1. Plot the location of all 'ASSAULT's for Ward 22

```{r comment="", results='hold'} 
res <- dbSendQuery(con, "
                   SELECT latitude,longitude
                   FROM crime
                   WHERE PrimaryType='ASSAULT' AND Ward='22'")
a <- fetch(res, n = -1)
dbClearResult(res)
plot(a$Longitude,a$Latitude,pch=".")
```


2. What's the most common (Lat,Long) for assaults in Ward 22. Add the point to your plot using the points() command. The points() command is new.  It's simply a function that draws a point (or sequence of points) at the specified coordinates. 

```{r comment="", results='hold'} 
res <- dbSendQuery(con, "
        SELECT COUNT(*) as crimecount,longitude, latitude
        FROM crime
        WHERE primarytype='ASSAULT' and ward='22'
        GROUP BY longitude, latitude")
a <- fetch(res, n=-1)
dbClearResult(res)
points(a[which.max(a$crimecount), 2:3],pch=16, col="salmon",cex=4)
a[which.max(a$crimecount),2:3]
```

#One More SQL Tip

SQL sometimes has a hard time recognizing a column name with a period (.) in it.  For example, if you were to run the following query, you might get a message that there is no column called Crime.Type when, in fact, there is such a column in your dataset.
res <- dbSendQuery(con, "
                   SELECT Crime.Type, Longitude, Latitude
                   FROM oshkoshcrime") 
fetch(res, n = 10)

So, to get around this, just put brackets around Crime.Type so that the new query is:
res <- dbSendQuery(con, "
                   SELECT [Crime.Type], Longitude, Latitude
                   FROM oshkoshcrime") 
fetch(res, n = 10)
And, of course, you could also just change the column name to something without a period.
